write.csv(JOLs, file = "ex1a JOLs.csv", row.names = F)
####Set up Free Recall data for scoring####
##Start by gathering all of the data
#Item JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Item")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#Global JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/List")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Read")
files3 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat3 = do.call(rbind, lapply(files3, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat3$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
##get versions and usernames
#v1 = dat[ , c(1, 9)]
#v2 = dat2[ , c(1, 9)]
#v3 = dat3[ , c(1, 9)]
#vs = rbind(v1, v2, v3)
#vs$dupe = duplicated(vs$Username)
#vs2 = subset(vs,
# vs$dupe == FALSE)
#write.csv(vs2[ , -3], file = "1a versions.csv", row.names = F)
#get mean JOLs
library(reshape)
dat$Response.JOL[dat$Response.JOL > 100] = NA
dat2$Response.JOL[dat2$Response.JOL > 100] = NA
dat1.JOL = cast(dat, Username ~ Stimuli.Stimuli.Notes, value = "Response.JOL", mean, na.rm = T)
dat2.JOL = cast(dat2, Username ~ Stimuli.Stimuli.Notes, value = "Response.JOL", mean, na.rm = T)
dat1.JOL = dat1.JOL[ , -2]
dat2.JOL = dat2.JOL[ , -2]
dat1.JOL$encoding = rep("item")
dat2.JOL$encoding = rep("global")
JOLs = rbind(dat1.JOL, dat2.JOL)
View(dat2)
View(dat2.JOL)
dat$Response.JOL[dat$Response.JOL > 100] = NA
dat$Response.JOL = as.numeric(dat$Response.JOL)
dat2$Response.JOL = as.numeric(dat2$Response.JOL)
View(dat2)
dat$Response.JOL[dat$Response.JOL > 100] = NA
dat2$Response.JOL[dat2$Response.JOL > 100] = NA
dat1.JOL = cast(dat, Username ~ Stimuli.Stimuli.Notes, value = "Response.JOL", mean, na.rm = T)
dat2.JOL = cast(dat2, Username ~ Stimuli.Stimuli.Notes, value = "Response.JOL", mean, na.rm = T)
View(dat2.JOL)
dat2.JOL = cast(dat2, Username ~ procedure.proecdure.Notes, value = "Response.JOL", mean, na.rm = T)
dat2.JOL = cast(dat2, Username ~ Procedure.Procedure.Notes, value = "Response.JOL", mean, na.rm = T)
View(dat1.JOL)
dat2.JOL = dat2.JOL[ , -c(2:3)]
dat1.JOL$encoding = rep("item")
dat2.JOL$encoding = rep("global")
JOLs = rbind(dat1.JOL, dat2.JOL)
####Set up Free Recall data for scoring####
##Start by gathering all of the data
#Item JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Item")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#Global JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/List")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Read")
files3 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat3 = do.call(rbind, lapply(files3, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat3$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
##get versions and usernames
#v1 = dat[ , c(1, 9)]
#v2 = dat2[ , c(1, 9)]
#v3 = dat3[ , c(1, 9)]
#vs = rbind(v1, v2, v3)
#vs$dupe = duplicated(vs$Username)
#vs2 = subset(vs,
# vs$dupe == FALSE)
#write.csv(vs2[ , -3], file = "1a versions.csv", row.names = F)
#get mean JOLs
library(reshape)
dat$Response.JOL = as.numeric(dat$Response.JOL)
dat2$Response.JOL = as.numeric(dat2$Response.JOL)
dat$Response.JOL[dat$Response.JOL > 100] = NA
dat2$Response.JOL[dat2$Response.JOL > 100] = NA
dat1.JOL = cast(dat, Username ~ Stimuli.Stimuli.Notes, value = "Response.JOL", mean, na.rm = T)
dat2.JOL = cast(dat2, Username ~ Procedure.Procedure.Notes, value = "Response.JOL", mean, na.rm = T)
dat1.JOL = dat1.JOL[ , -2]
dat2.JOL = dat2.JOL[ , -c(2:3)]
dat1.JOL$encoding = rep("item")
dat2.JOL$encoding = rep("global")
JOLs = rbind(dat1.JOL, dat2.JOL)
write.csv(JOLs, file = "ex1a JOLs.csv", row.names = F)
####Set up Free Recall data for scoring####
##Start by gathering all of the data
#Item JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Item")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#Global JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/List")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Read")
files3 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat3 = do.call(rbind, lapply(files3, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat3$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
##get versions and usernames
#v1 = dat[ , c(1, 9)]
#v2 = dat2[ , c(1, 9)]
#v3 = dat3[ , c(1, 9)]
#vs = rbind(v1, v2, v3)
#vs$dupe = duplicated(vs$Username)
#vs2 = subset(vs,
# vs$dupe == FALSE)
#write.csv(vs2[ , -3], file = "1a versions.csv", row.names = F)
#get mean JOLs
#library(reshape)
#dat$Response.JOL = as.numeric(dat$Response.JOL)
#dat2$Response.JOL = as.numeric(dat2$Response.JOL)
#dat$Response.JOL[dat$Response.JOL > 100] = NA
#dat2$Response.JOL[dat2$Response.JOL > 100] = NA
#dat1.JOL = cast(dat, Username ~ Stimuli.Stimuli.Notes, value = "Response.JOL", mean, na.rm = T)
#dat2.JOL = cast(dat2, Username ~ Procedure.Procedure.Notes, value = "Response.JOL", mean, na.rm = T)
#dat1.JOL = dat1.JOL[ , -2]
#dat2.JOL = dat2.JOL[ , -c(2:3)]
#dat1.JOL$encoding = rep("item")
#dat2.JOL$encoding = rep("global")
#JOLs = rbind(dat1.JOL, dat2.JOL)
#write.csv(JOLs, file = "ex1a JOLs.csv", row.names = F)
View(dat)
####Get Encoding Latencies####
dat.E = subset(dat,
dat$Procedure.Procedure.Notes == "Related" | dat$Procedure.Procedure.Notes == "Unrelated")
View(dat.E)
table(dat.E$Procedure.Procedure.Notes)
table(dat.E$Procedure.Shuffle)
dat.E$Procedure.Shuffle == "U1" | dat.E$Procedure.Shuffle == "U2"
dat.E = subset(dat.E,
dat.E$Procedure.Shuffle == "R1" | dat.E$Procedure.Shuffle == "R2" |
dat.E$Procedure.Shuffle == "U1" | dat.E$Procedure.Shuffle == "U2")
dat2.E = subset(dat2.E,
dat2.E$Procedure.Shuffle == "R1" | dat2.E$Procedure.Shuffle == "R2" |
dat2.E$Procedure.Shuffle == "U1" | dat2.E$Procedure.Shuffle == "U2")
dat2.E = subset(dat2,
dat2$Procedure.Procedure.Notes == "Related" | dat2$Procedure.Procedure.Notes == "Unrelated")
dat2.E = subset(dat2.E,
dat2.E$Procedure.Shuffle == "R1" | dat2.E$Procedure.Shuffle == "R2" |
dat2.E$Procedure.Shuffle == "U1" | dat2.E$Procedure.Shuffle == "U2")
dat3.E = subset(dat3,
dat3$Procedure.Procedure.Notes == "Related" | dat3$Procedure.Procedure.Notes == "Unrelated")
dat3.E = subset(dat3.E,
dat3.E$Procedure.Shuffle == "R1" | dat3.E$Procedure.Shuffle == "R2" |
dat3.E$Procedure.Shuffle == "U1" | dat3.E$Procedure.Shuffle == "U2")
View(dat3.E)
library(reshape)
dat1.Encoding = cast(dat.E, Username ~ Stimuli.Stimuli.Notes, value = "Response.RT", mean, na.rm = T)
View(dat1.Encoding)
dat2.Encoding = cast(dat2.E, Username ~ Stimuli.Stimuli.Notes, value = "Response.RT", mean, na.rm = T)
dat3.Encoding = cast(dat3.E, Username ~ Stimuli.Stimuli.Notes, value = "Response.RT", mean, na.rm = T)
dat1.Encoding$Encoding = rep("item")
dat2.Encoding$Encoding = rep("global")
View(dat.E)
dat3.Encoding$Encoding = rep("read")
write.csv(rbind(dat1.Encoding, dat2.Encoding, dat3.Encoding), file = "Ex1a Encoding.csv", row.names = F)
####Set up Free Recall data for scoring####
##Start by gathering all of the data
#Item JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Item")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#Global JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/List")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Read")
files3 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat3 = do.call(rbind, lapply(files3, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat3$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
##get versions and usernames
#v1 = dat[ , c(1, 9)]
#v2 = dat2[ , c(1, 9)]
#v3 = dat3[ , c(1, 9)]
#vs = rbind(v1, v2, v3)
#vs$dupe = duplicated(vs$Username)
#vs2 = subset(vs,
# vs$dupe == FALSE)
#write.csv(vs2[ , -3], file = "1a versions.csv", row.names = F)
#get mean JOLs
#library(reshape)
#dat$Response.JOL = as.numeric(dat$Response.JOL)
#dat2$Response.JOL = as.numeric(dat2$Response.JOL)
#dat$Response.JOL[dat$Response.JOL > 100] = NA
#dat2$Response.JOL[dat2$Response.JOL > 100] = NA
#dat1.JOL = cast(dat, Username ~ Stimuli.Stimuli.Notes, value = "Response.JOL", mean, na.rm = T)
#dat2.JOL = cast(dat2, Username ~ Procedure.Procedure.Notes, value = "Response.JOL", mean, na.rm = T)
#dat1.JOL = dat1.JOL[ , -2]
#dat2.JOL = dat2.JOL[ , -c(2:3)]
#dat1.JOL$encoding = rep("item")
#dat2.JOL$encoding = rep("global")
#JOLs = rbind(dat1.JOL, dat2.JOL)
#write.csv(JOLs, file = "ex1a JOLs.csv", row.names = F)
####Get Encoding Latencies####
dat.E = subset(dat,
dat$Procedure.Procedure.Notes == "Related" | dat$Procedure.Procedure.Notes == "Unrelated")
dat2.E = subset(dat2,
dat2$Procedure.Procedure.Notes == "Related" | dat2$Procedure.Procedure.Notes == "Unrelated")
dat3.E = subset(dat3,
dat3$Procedure.Procedure.Notes == "Related" | dat3$Procedure.Procedure.Notes == "Unrelated")
table(dat.E$Procedure.Shuffle)
dat.E = subset(dat.E,
dat.E$Procedure.Shuffle == "R1" | dat.E$Procedure.Shuffle == "R2" |
dat.E$Procedure.Shuffle == "U1" | dat.E$Procedure.Shuffle == "U2")
dat2.E = subset(dat2.E,
dat2.E$Procedure.Shuffle == "R1" | dat2.E$Procedure.Shuffle == "R2" |
dat2.E$Procedure.Shuffle == "U1" | dat2.E$Procedure.Shuffle == "U2")
dat3.E = subset(dat3.E,
dat3.E$Procedure.Shuffle == "R1" | dat3.E$Procedure.Shuffle == "R2" |
dat3.E$Procedure.Shuffle == "U1" | dat3.E$Procedure.Shuffle == "U2")
library(reshape)
##omit extreme scores
dat.E$Response.RT[dat.E$Response.RT > 1000] = NA
##omit extreme scores
dat.E$Response.RT[dat.E$Response.RT > 10000] = NA
####Set up Free Recall data for scoring####
##Start by gathering all of the data
#Item JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Item")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#Global JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/List")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Read")
files3 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat3 = do.call(rbind, lapply(files3, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat3$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
##get versions and usernames
#v1 = dat[ , c(1, 9)]
#v2 = dat2[ , c(1, 9)]
#v3 = dat3[ , c(1, 9)]
#vs = rbind(v1, v2, v3)
#vs$dupe = duplicated(vs$Username)
#vs2 = subset(vs,
# vs$dupe == FALSE)
#write.csv(vs2[ , -3], file = "1a versions.csv", row.names = F)
#get mean JOLs
#library(reshape)
#dat$Response.JOL = as.numeric(dat$Response.JOL)
#dat2$Response.JOL = as.numeric(dat2$Response.JOL)
#dat$Response.JOL[dat$Response.JOL > 100] = NA
#dat2$Response.JOL[dat2$Response.JOL > 100] = NA
#dat1.JOL = cast(dat, Username ~ Stimuli.Stimuli.Notes, value = "Response.JOL", mean, na.rm = T)
#dat2.JOL = cast(dat2, Username ~ Procedure.Procedure.Notes, value = "Response.JOL", mean, na.rm = T)
#dat1.JOL = dat1.JOL[ , -2]
#dat2.JOL = dat2.JOL[ , -c(2:3)]
#dat1.JOL$encoding = rep("item")
#dat2.JOL$encoding = rep("global")
#JOLs = rbind(dat1.JOL, dat2.JOL)
#write.csv(JOLs, file = "ex1a JOLs.csv", row.names = F)
####Get Encoding Latencies####
dat.E = subset(dat,
dat$Procedure.Procedure.Notes == "Related" | dat$Procedure.Procedure.Notes == "Unrelated")
dat2.E = subset(dat2,
dat2$Procedure.Procedure.Notes == "Related" | dat2$Procedure.Procedure.Notes == "Unrelated")
dat3.E = subset(dat3,
dat3$Procedure.Procedure.Notes == "Related" | dat3$Procedure.Procedure.Notes == "Unrelated")
table(dat.E$Procedure.Shuffle)
dat.E = subset(dat.E,
dat.E$Procedure.Shuffle == "R1" | dat.E$Procedure.Shuffle == "R2" |
dat.E$Procedure.Shuffle == "U1" | dat.E$Procedure.Shuffle == "U2")
dat2.E = subset(dat2.E,
dat2.E$Procedure.Shuffle == "R1" | dat2.E$Procedure.Shuffle == "R2" |
dat2.E$Procedure.Shuffle == "U1" | dat2.E$Procedure.Shuffle == "U2")
dat3.E = subset(dat3.E,
dat3.E$Procedure.Shuffle == "R1" | dat3.E$Procedure.Shuffle == "R2" |
dat3.E$Procedure.Shuffle == "U1" | dat3.E$Procedure.Shuffle == "U2")
library(reshape)
##omit extreme scores
dat.E$Response.RT[dat.E$Response.RT > 9999] = NA
dat.E$Response.RT[dat.E$Response.RT < 1000] = NA
dat3.E$Response.RT[dat3.E$Response.RT > 9999] = NA
dat3.E$Response.RT[dat3.E$Response.RT < 1000] = NA
dat2.E$Response.RT[dat2.E$Response.RT > 9999] = NA
dat2.E$Response.RT[dat2.E$Response.RT < 1000] = NA
####Set up Free Recall data for scoring####
##Start by gathering all of the data
#Item JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Item")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#Global JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/List")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Read")
files3 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat3 = do.call(rbind, lapply(files3, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat3$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
##get versions and usernames
#v1 = dat[ , c(1, 9)]
#v2 = dat2[ , c(1, 9)]
#v3 = dat3[ , c(1, 9)]
#vs = rbind(v1, v2, v3)
#vs$dupe = duplicated(vs$Username)
#vs2 = subset(vs,
# vs$dupe == FALSE)
#write.csv(vs2[ , -3], file = "1a versions.csv", row.names = F)
#get mean JOLs
#library(reshape)
#dat$Response.JOL = as.numeric(dat$Response.JOL)
#dat2$Response.JOL = as.numeric(dat2$Response.JOL)
#dat$Response.JOL[dat$Response.JOL > 100] = NA
#dat2$Response.JOL[dat2$Response.JOL > 100] = NA
#dat1.JOL = cast(dat, Username ~ Stimuli.Stimuli.Notes, value = "Response.JOL", mean, na.rm = T)
#dat2.JOL = cast(dat2, Username ~ Procedure.Procedure.Notes, value = "Response.JOL", mean, na.rm = T)
#dat1.JOL = dat1.JOL[ , -2]
#dat2.JOL = dat2.JOL[ , -c(2:3)]
#dat1.JOL$encoding = rep("item")
#dat2.JOL$encoding = rep("global")
#JOLs = rbind(dat1.JOL, dat2.JOL)
#write.csv(JOLs, file = "ex1a JOLs.csv", row.names = F)
####Get Encoding Latencies####
dat.E = subset(dat,
dat$Procedure.Procedure.Notes == "Related" | dat$Procedure.Procedure.Notes == "Unrelated")
dat2.E = subset(dat2,
dat2$Procedure.Procedure.Notes == "Related" | dat2$Procedure.Procedure.Notes == "Unrelated")
dat3.E = subset(dat3,
dat3$Procedure.Procedure.Notes == "Related" | dat3$Procedure.Procedure.Notes == "Unrelated")
table(dat.E$Procedure.Shuffle)
dat.E = subset(dat.E,
dat.E$Procedure.Shuffle == "R1" | dat.E$Procedure.Shuffle == "R2" |
dat.E$Procedure.Shuffle == "U1" | dat.E$Procedure.Shuffle == "U2")
dat2.E = subset(dat2.E,
dat2.E$Procedure.Shuffle == "R1" | dat2.E$Procedure.Shuffle == "R2" |
dat2.E$Procedure.Shuffle == "U1" | dat2.E$Procedure.Shuffle == "U2")
dat3.E = subset(dat3.E,
dat3.E$Procedure.Shuffle == "R1" | dat3.E$Procedure.Shuffle == "R2" |
dat3.E$Procedure.Shuffle == "U1" | dat3.E$Procedure.Shuffle == "U2")
library(reshape)
##omit extreme scores
dat.E$Response.RT[dat.E$Response.RT > 9999] = NA
dat.E$Response.RT[dat.E$Response.RT < 1000] = NA
dat2.E$Response.RT[dat2.E$Response.RT > 9999] = NA
dat2.E$Response.RT[dat2.E$Response.RT < 1000] = NA
dat3.E$Response.RT[dat3.E$Response.RT > 9999] = NA
dat3.E$Response.RT[dat3.E$Response.RT < 1000] = NA
dat1.Encoding = cast(dat.E, Username ~ Stimuli.Stimuli.Notes, value = "Response.RT", mean, na.rm = T)
dat2.Encoding = cast(dat2.E, Username ~ Stimuli.Stimuli.Notes, value = "Response.RT", mean, na.rm = T)
dat3.Encoding = cast(dat3.E, Username ~ Stimuli.Stimuli.Notes, value = "Response.RT", mean, na.rm = T)
View(dat1.Encoding)
dat1.Encoding$Encoding = rep("item")
dat2.Encoding$Encoding = rep("global")
dat3.Encoding$Encoding = rep("read")
write.csv(rbind(dat1.Encoding, dat2.Encoding, dat3.Encoding), file = "Ex1a Encoding.csv", row.names = F)
####Set up Free Recall data for scoring####
##Start by gathering all of the data
#Item JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Item")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#Global JOLs
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/List")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/DRM-Reactivity/3 Output/Ex 1A/Read")
files3 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat3 = do.call(rbind, lapply(files3, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat3$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
##get versions and usernames
#v1 = dat[ , c(1, 9)]
#v2 = dat2[ , c(1, 9)]
#v3 = dat3[ , c(1, 9)]
#vs = rbind(v1, v2, v3)
#vs$dupe = duplicated(vs$Username)
#vs2 = subset(vs,
# vs$dupe == FALSE)
#write.csv(vs2[ , -3], file = "1a versions.csv", row.names = F)
#get mean JOLs
#library(reshape)
#dat$Response.JOL = as.numeric(dat$Response.JOL)
#dat2$Response.JOL = as.numeric(dat2$Response.JOL)
#dat$Response.JOL[dat$Response.JOL > 100] = NA
#dat2$Response.JOL[dat2$Response.JOL > 100] = NA
#dat1.JOL = cast(dat, Username ~ Stimuli.Stimuli.Notes, value = "Response.JOL", mean, na.rm = T)
#dat2.JOL = cast(dat2, Username ~ Procedure.Procedure.Notes, value = "Response.JOL", mean, na.rm = T)
#dat1.JOL = dat1.JOL[ , -2]
#dat2.JOL = dat2.JOL[ , -c(2:3)]
#dat1.JOL$encoding = rep("item")
#dat2.JOL$encoding = rep("global")
#JOLs = rbind(dat1.JOL, dat2.JOL)
#write.csv(JOLs, file = "ex1a JOLs.csv", row.names = F)
####Get Encoding Latencies####
dat.E = subset(dat,
dat$Procedure.Procedure.Notes == "Related" | dat$Procedure.Procedure.Notes == "Unrelated")
dat2.E = subset(dat2,
dat2$Procedure.Procedure.Notes == "Related" | dat2$Procedure.Procedure.Notes == "Unrelated")
dat3.E = subset(dat3,
dat3$Procedure.Procedure.Notes == "Related" | dat3$Procedure.Procedure.Notes == "Unrelated")
table(dat.E$Procedure.Shuffle)
dat.E = subset(dat.E,
dat.E$Procedure.Shuffle == "R1" | dat.E$Procedure.Shuffle == "R2" |
dat.E$Procedure.Shuffle == "U1" | dat.E$Procedure.Shuffle == "U2")
dat2.E = subset(dat2.E,
dat2.E$Procedure.Shuffle == "R1" | dat2.E$Procedure.Shuffle == "R2" |
dat2.E$Procedure.Shuffle == "U1" | dat2.E$Procedure.Shuffle == "U2")
dat3.E = subset(dat3.E,
dat3.E$Procedure.Shuffle == "R1" | dat3.E$Procedure.Shuffle == "R2" |
dat3.E$Procedure.Shuffle == "U1" | dat3.E$Procedure.Shuffle == "U2")
library(reshape)
##omit extreme scores
dat.E$Response.RT[dat.E$Response.RT > 9999] = NA
dat.E$Response.RT[dat.E$Response.RT < 1000] = NA
dat2.E$Response.RT[dat2.E$Response.RT > 9999] = NA
dat2.E$Response.RT[dat2.E$Response.RT < 1000] = NA
dat3.E$Response.RT[dat3.E$Response.RT > 9999] = NA
dat3.E$Response.RT[dat3.E$Response.RT < 1000] = NA
dat1.Encoding = cast(dat.E, Username ~ Stimuli.Stimuli.Notes, value = "Response.RT", mean, na.rm = T)
dat2.Encoding = cast(dat2.E, Username ~ Stimuli.Stimuli.Notes, value = "Response.RT", mean, na.rm = T)
dat3.Encoding = cast(dat3.E, Username ~ Stimuli.Stimuli.Notes, value = "Response.RT", mean, na.rm = T)
dat1.Encoding$Encoding = rep("item")
dat2.Encoding$Encoding = rep("global")
dat3.Encoding$Encoding = rep("read")
View(dat)
View(dat2)
table(dat2$Procedure.Shuffle)
##get global Judgment RTs
dat.g = subset(dat2, dat2$Procedure.Shuffle == "JOL1" | dat2$Procedure.Shuffle == "JOL2" |
dat2$Procedure.Shuffle == "JOL3" | dat2$Procedure.Shuffle == "JOL4")
View(dat.g)
